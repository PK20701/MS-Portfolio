# Customer Churn Prediction Pipeline

This project implements a full end-to-end MLOps pipeline for predicting customer churn. It covers everything from data generation and ingestion to model training, versioning, and prediction. The entire workflow is automated and orchestrated using modern MLOps tools.

## MLOps Features

This project incorporates several MLOps best practices to ensure reproducibility, scalability, and maintainability.

*   **Orchestration with Prefect**: The entire pipeline is defined as a workflow in `src/orchestrate.py`, ensuring that all steps run in the correct order, with proper dependency management and error handling.
*   **Experiment Tracking with MLflow**: All model training runs, parameters, metrics, and artifacts are logged to MLflow, providing a complete history of every experiment.
*   **Feature Store**: A lightweight, file-based feature store (`src/feature_store.py`) provides a centralized, versioned, and documented source of features for model training, decoupling feature engineering from model development.
*   **Data Versioning with DVC**: Large data files are versioned with DVC and tracked in Git, ensuring that every commit corresponds to a specific, reproducible version of the data.
*   **Data Validation**: Raw data is validated against expectations using Evidently AI to detect drift or quality issues early in the pipeline.
*   **Dependency and Environment Management**: A `setup.sh` script and `requirements.txt` file ensure a consistent and reproducible Python environment.


## Project Overview

### Project Structure

```
├── data/
│   ├── raw/          # Raw, immutable data
│   ├── prepared/     # Cleaned and encoded data
│   └── transformed/  # Scaled features for the Feature Store
├── logs/             # Log files for each pipeline step
├── mlruns/           # MLflow experiment tracking data (autogenerated)
├── notebooks/        # Jupyter notebooks for exploration and analysis
│   └── eda.ipynb     # Example notebook for exploratory data analysis
├── reports/          # Data validation reports (autogenerated)
├── src/              # All Python source code
│   ├── __init__.py
│   ├── orchestrate.py                # Main Prefect pipeline orchestrator
│   ├── feature_store.py              # Feature definitions and retrieval API
│   ├── generate_csv_data.py          # Generates synthetic customer account data
│   ├── generate_api_data.py          # Generates synthetic customer interaction data
│   ├── data_ingest_kaggle.py         # Downloads data from Kaggle
│   ├── mock_api.py                   # Mock API server to simulate fetching real-time data
│   ├── ingest.py                     # Ingests data from all raw sources
│   ├── validate_raw_data.py          # Validates raw data using Evidently AI
│   ├── prepare_data.py               # Cleans, encodes, and prepares data
│   ├── transform_and_store.py        # Creates features and stores them in the feature store
│   ├── train_model_with_feature_store.py # Trains model and logs to MLflow
│   └── predict.py                    # Loads a model from the MLflow registry for inference
├── requirements.txt  # Project dependencies
└── setup.sh          # Setup script for environment and data
```
### Project Data Flow

![alt text](image.png)

### Pipeline Design

    o   src/orchestrate.py:
        The main conductor that defines the workflow using Prefect and calls all other scripts in the correct order. 
    o	src/generate_csv_data.py & src/generate_api_data.py: 
        Used when data_source=synthetic. These scripts create mock customer account and interaction data.
    o	src/data_ingest_kaggle.py: 
        Used when data_source=kaggle. This script downloads the real-world dataset from Kaggle. 
    o   src/mock_api.py: 
        A simple Flask server that starts up to simulate a live API endpoint for serving customer interaction data. It is automatically started and stopped by the orchestrator. 
    o   src/ingest.py: 
        Fetches data from the raw CSV files and the mock API, combining them into a single, unified dataset. 
    o   src/validate_raw_data.py:  
        Uses Evidently AI to generate a data validation report, checking for drift or quality issues in the raw data.
    o   src/prepare_data.py: 
        Cleans the ingested data by handling missing values, correcting data types, and performing initial encoding. 
    o   src/transform_and_store.py: 
        Performs feature engineering based on definitions in the feature store, scales the data, and saves the final features to the offline store (data/transformed/). 
    o   src/train_model_with_feature_store.py: 
        Retrieves the latest features from the feature store, trains multiple models (e.g., Logistic Regression, Random Forest), and logs all experiments, parameters, metrics, and model artifacts to MLflow.
 


## Setup and RunBook

Follow these steps to set up and run the pipeline on a new machine.

### 1. Prerequisites

*   **Git**: To clone the repository.
*   **Bash-compatible shell** (like Git Bash on Windows, or any standard Linux/macOS terminal): To run the setup script.
*   **Python 3.8+**: The setup script will verify this for you.

### 2. Setup

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/PK20701/MS-Portfolio.git
    cd DMML/Customer_churn_analysis
    ```

2.  **Run the setup script:**
    This script automates the entire setup process. It will:
    *   Check for the correct Python version.
    *   Create a virtual environment in `.venv/`.
    *   Install all required packages from `requirements.txt`.
    *   Configure a local DVC remote and pull the versioned data.

    ```bash
    bash setup.sh
    ```

3.  **Activate the virtual environment:**
    After the setup is complete, activate the newly created environment before running the pipeline:
    ```bash
    source .venv/bin/activate  # On Windows, use `.venv\Scripts\activate`
    ```

### 3. Running the Pipeline

To execute the entire MLOps pipeline, run the orchestration script:

This pipeline can be run with two different data sources by providing a parameter to the main flow:
*   **synthetic** (default): Generates mock data locally.
*   **kaggle**: Downloads the "Telco Customer Churn" dataset from Kaggle.

To run with the default synthetic data:
```bash
python src/orchestrate.py
```

To run with the real-world Kaggle dataset:
```bash
python src/orchestrate.py kaggle
```

This script will:
1.  Generate or download raw data based on the `data_source` parameter.
2.  Ingest and validate it using Evidently AI.
3.  Transform features and update the feature store.
4.  Train the churn prediction model.
5.  Log experiments and metrics to MLflow.

### 4. Viewing Results - Model Experiements

*   **Logs**: Check the `logs/` directory for detailed logs from each pipeline step.
*   **MLflow**: Launch the MLflow UI to view experiment runs, parameters, and metrics:
    ```bash
    mlflow ui
    ```
    Then navigate to `http://127.0.0.1:5000` in your browser.
*   **Data Validation Reports**: Open `reports/data_validation_report.html` to see the Evidently AI data validation report.
Sample - 
![alt text](image-1.png)

### 5. Viewing Results - Orchestrator run

*   **Prefect**: Launch the prefect UI to view orechstration runs:
    ```bash
    prefect server start
    ```
    Check out the dashboard at http://127.0.0.1:4200
    sample - 
    ![alt text](image.png) 